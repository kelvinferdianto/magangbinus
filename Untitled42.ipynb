{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled42.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbJFv6e2h5YS"
      },
      "source": [
        "import urllib\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import time\r\n",
        "from datetime import date\r\n",
        "\r\n",
        "url = \"http://indeks.kompas.com/indeks/index/news\"\r\n",
        "\r\n",
        "#ambil hari ini\r\n",
        "today = date.today().strftime(\"%d%m%Y\")\r\n",
        "filename = \"brt-%s.txt\" % today\r\n",
        "filelink = \"link-%s.txt\" % today\r\n",
        "\r\n",
        "def getUrl(url):\r\n",
        "    '''ambil url tiap berita di indeks'''\r\n",
        "    tautan = []\r\n",
        "    url = urllib.urlopen(url)\r\n",
        "\r\n",
        "    result = url.read()\r\n",
        "    url.close()\r\n",
        "    soup = BeautifulSoup(result, \"html.parser\")\r\n",
        "\r\n",
        "    for link in soup.find_all('h3'):\r\n",
        "        for l in link.find_all('a'):\r\n",
        "            isi = l.get('href')\r\n",
        "            tautan.append(isi)\r\n",
        "    return tautan\r\n",
        "\r\n",
        "def getIndeks(url):\r\n",
        "    i = 1\r\n",
        "    tautans = []\r\n",
        "    tautan = getUrl(url)\r\n",
        "    while (len(tautan) != 0):\r\n",
        "        url = \"http://indeks.kompas.com/indeks/index/news?p=%d\" %i\r\n",
        "        print url\r\n",
        "        i += 1\r\n",
        "        tautan = getUrl(url)\r\n",
        "        tautans += tautan\r\n",
        "\r\n",
        "    print len(tautans)\r\n",
        "    bf = open(filelink, \"w\")\r\n",
        "    for t in tautans:\r\n",
        "        bf.write(t)\r\n",
        "        bf.write(\"\\n\")\r\n",
        "    bf.close()\r\n",
        "\r\n",
        "def getBerita(url):\r\n",
        "    url = urllib.urlopen(url)\r\n",
        "    result = url.read()\r\n",
        "    url.close()\r\n",
        "    isiberita = \"\"\r\n",
        "\r\n",
        "    soup = BeautifulSoup(result, \"html.parser\")\r\n",
        "    for berita in soup.find_all('div', {'class':'kcm-read-text'}):\r\n",
        "        isiberita += berita.get_text().encode(\"utf-8\")\r\n",
        "    bf = open(filename, 'a')\r\n",
        "    bf.write(isiberita)\r\n",
        "    bf.write(\"\\n\")\r\n",
        "    bf.close()\r\n",
        "\r\n",
        "def getLinkFromFile():\r\n",
        "    '''Ambil berita dari link yang sudah disimpan di link-tgl.txt'''\r\n",
        "    print \"Ambil berita dari link tanggal %s. \" % today\r\n",
        "    bf = open(filelink, 'r')\r\n",
        "    i = 0\r\n",
        "    for l in bf:\r\n",
        "        print l\r\n",
        "        getBerita(l)\r\n",
        "    bf.close()\r\n",
        "\r\n",
        "#mainkan\r\n",
        "getIndeks(url)\r\n",
        "getLinkFromFile()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}